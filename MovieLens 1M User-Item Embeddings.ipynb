{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach\n",
    "\n",
    "An implementation expanding on the code fragment in [Alkahest](http://www.fenris.org/)'s blog post [Collaborative Filtering in Keras](http://www.fenris.org/2016/03/07/collaborative-filtering-in-keras), using the [MovieLens 1M Dataset](http://grouplens.org/datasets/movielens/1m/) for training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Embedding, Reshape, Merge\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adamax\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants\n",
    "The MovieLens 1M Dataset can be downloaded from http://files.grouplens.org/datasets/movielens/ml-1m.zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = '.' # Modify this if needed to the local directory that the MovieLens 1M Dataset has been unzipped into. \n",
    "MOVIELENS_DIR = BASE_DIR + '/ml-1m/'\n",
    "FACTORS = 20\n",
    "N_USERS_IN_RATINGS = 6040\n",
    "N_MOVIES_IN_RATINGS = 3952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MovieLens 1M data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data about 6040 of 6040 users loaded.\n",
      "Data about 3883 of 3952 movies loaded.\n",
      "1000209 ratings loaded.\n"
     ]
    }
   ],
   "source": [
    "# User records are of the form: UserID::Gender::Age::Occupation::Zip-code\n",
    "user_data = {}\n",
    "user_records = open(os.path.join(MOVIELENS_DIR, 'users.dat'))\n",
    "for user in user_records:\n",
    "    values = user.split('::')\n",
    "    (userid, gender, age, occupation, zipcode) = values\n",
    "    user_data[int(userid)-1] = {'gender': gender, \n",
    "                              'age': age, \n",
    "                              'occupation': occupation, \n",
    "                              'zipcode': zipcode.strip()}\n",
    "user_records.close()\n",
    "print 'Data about', len(user_data), 'of', N_USERS_IN_RATINGS, 'users loaded.'\n",
    "\n",
    "# Movie records are of the form: MovieID::Title::Genres\n",
    "movie_data = {}\n",
    "movie_records = open(os.path.join(MOVIELENS_DIR, 'movies.dat'))\n",
    "for movie in movie_records:\n",
    "    values = movie.split('::')\n",
    "    (movieid, title, genres) = values\n",
    "    movie_data[int(movieid)-1] = {'title': title, 'genres': genres.strip().split('|')}\n",
    "movie_records.close()\n",
    "print 'Data about', len(movie_data), 'of', N_MOVIES_IN_RATINGS, 'movies loaded.'\n",
    "\n",
    "# Rating records are of the form UserID::MovieID::Rating::Timestamp\n",
    "rating_data = []\n",
    "rating_records = open(os.path.join(MOVIELENS_DIR, 'ratings.dat'))\n",
    "for rating in rating_records:\n",
    "    values = rating.split('::')\n",
    "    (userid, movieid, rating, timestamp) = values\n",
    "    rating_data.append([int(userid)-1, int(movieid)-1, int(rating)])\n",
    "rating_records.close()\n",
    "print len(rating_data), 'ratings loaded.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: [5852 5463 5681 ..., 1610  876 2037] , shape = (1000209,)\n",
      "Movies: [3500 2727 3860 ..., 3783 2715  234] , shape = (1000209,)\n",
      "Ratings: [1 4 3 ..., 4 4 4] , shape = (1000209,)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(rating_data)\n",
    "np.random.shuffle(data)\n",
    "data = data.T\n",
    "Users = data[0]\n",
    "print 'Users:', Users, ', shape =', Users.shape\n",
    "Movies = data[1]\n",
    "print 'Movies:', Movies, ', shape =', Movies.shape\n",
    "Ratings = data[2]\n",
    "print 'Ratings:', Ratings, ', shape =', Ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left = Sequential()\n",
    "left.add(Embedding(N_USERS_IN_RATINGS, FACTORS, input_length=1))\n",
    "left.add(Reshape((FACTORS,)))\n",
    "\n",
    "right = Sequential()\n",
    "right.add(Embedding(N_MOVIES_IN_RATINGS, FACTORS, input_length=1))\n",
    "right.add(Reshape((FACTORS,)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([left, right], mode='dot', dot_axes=1))\n",
    "model.compile(loss='mse', optimizer='adamax')\n",
    "callbacks = [EarlyStopping('val_loss', patience=2), ModelCheckpoint('movie_weights.h5', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900188 samples, validate on 100021 samples\n",
      "Epoch 1/15\n",
      "565s - loss: 11.1471 - val_loss: 5.4217\n",
      "Epoch 2/15\n",
      "609s - loss: 3.2400 - val_loss: 2.0896\n",
      "Epoch 3/15\n",
      "595s - loss: 1.6470 - val_loss: 1.3981\n",
      "Epoch 4/15\n",
      "593s - loss: 1.2226 - val_loss: 1.1470\n",
      "Epoch 5/15\n",
      "601s - loss: 1.0499 - val_loss: 1.0289\n",
      "Epoch 6/15\n",
      "597s - loss: 0.9649 - val_loss: 0.9651\n",
      "Epoch 7/15\n",
      "597s - loss: 0.9186 - val_loss: 0.9289\n",
      "Epoch 8/15\n",
      "599s - loss: 0.8916 - val_loss: 0.9070\n",
      "Epoch 9/15\n",
      "601s - loss: 0.8745 - val_loss: 0.8916\n",
      "Epoch 10/15\n",
      "609s - loss: 0.8629 - val_loss: 0.8818\n",
      "Epoch 11/15\n",
      "612s - loss: 0.8543 - val_loss: 0.8736\n",
      "Epoch 12/15\n",
      "613s - loss: 0.8473 - val_loss: 0.8672\n",
      "Epoch 13/15\n",
      "603s - loss: 0.8406 - val_loss: 0.8615\n",
      "Epoch 14/15\n",
      "614s - loss: 0.8344 - val_loss: 0.8558\n",
      "Epoch 15/15\n",
      "612s - loss: 0.8280 - val_loss: 0.8497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x113173290>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Users, Movies], Ratings, nb_epoch=15, validation_split=.1, verbose=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
